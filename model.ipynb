{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Procedure Comparison Chatbot - Overview\n",
        "\n",
        "This Jupyter Notebook implements a bilingual procedure comparison chatbot that processes PDF documents in English and French, extracts procedures, and enables querying and comparison through a chatbot interface. The project follows the **CRISP-DM methodology**, a structured and iterative framework for data mining, ensuring clear objectives, systematic development, and thorough evaluation. The notebook is organized into six CRISP-DM phases: **Business Understanding**, **Data Understanding**, **Data Preparation**, **Modeling**, **Evaluation**, and **Deployment**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Goals\n",
        "\n",
        "The primary goal is to create a robust chatbot capable of:\n",
        "- **Processing Bilingual PDFs**: Extract procedures from PDF documents in English and French, handling both text-based and scanned documents.\n",
        "- **Query Handling**: Support user queries to list, describe, execute, or compare procedures with accurate intent recognition.\n",
        "- **Bilingual Support**: Provide seamless responses in English and French, respecting user language preferences.\n",
        "- **Scalable Deployment**: Deliver the chatbot through a web interface that is user-friendly and production-ready.\n",
        "- **Performance Evaluation**: Assess the system’s accuracy in intent classification, response quality, and response time to ensure reliability.\n",
        "\n",
        "The system aims to streamline access to procedural information, making it easier for users to understand and compare processes across languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CRISP-DM Methodology and Process\n",
        "\n",
        "The project leverages the **CRISP-DM methodology**, which provides a structured approach to data mining and ensures iterative improvement. The process is divided into the following phases:\n",
        "- **Business Understanding**: Define objectives, configure logging, set up data models, and establish bilingual prompt templates for consistent responses.\n",
        "- **Data Understanding**: Verify and explore PDF files in English and French directories to understand the data structure and availability.\n",
        "- **Data Preparation**: Process PDFs to extract text and procedures, optimize text chunking parameters, and store data for efficient retrieval.\n",
        "- **Modeling**: Implement a query handler that uses intent classification, document retrieval, and large language model (LLM) integration to generate responses.\n",
        "- **Evaluation**: Assess chatbot performance using metrics like precision, recall, F1-score for intent classification, cosine similarity for response quality, and response times.\n",
        "- **Deployment**: Launch the chatbot as a web application using Flask and Waitress, ensuring scalability and user accessibility.\n",
        "\n",
        "Each phase builds on the previous one, with iterative refinements to improve performance and usability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choice of Methods\n",
        "\n",
        "The project employs a combination of methods to achieve its goals:\n",
        "- **PDF Processing**: Uses `PyPDFLoader` for extracting text from text-based PDFs and `pdf2image` with `pytesseract` for OCR on scanned documents, ensuring robust handling of diverse PDF formats.\n",
        "- **Language Detection**: Utilizes `fasttext` for accurate detection of English and French in documents and queries, enabling bilingual support.\n",
        "- **Intent Classification**: Employs `DistilBERT`, a lightweight transformer model, for efficient and accurate classification of user intents (e.g., list, question, detail, execute, compare).\n",
        "- **Text Chunking and Retrieval**: Combines `RecursiveCharacterTextSplitter` for splitting documents into manageable chunks and `EnsembleRetriever` (combining BM25 and Chroma) for hybrid search, balancing keyword-based and semantic retrieval.\n",
        "- **Parameter Optimization**: Applies `optuna` to optimize chunking and retrieval parameters, ensuring efficient document processing and query performance.\n",
        "- **LLM Integration**: Integrates `HuggingFaceEndpoint` with Mixtral-8x7B for generating natural and contextually relevant responses.\n",
        "- **Web Interface**: Uses Flask for a lightweight web framework and Waitress for production-grade serving, providing a scalable and user-friendly interface.\n",
        "\n",
        "These methods were chosen for their efficiency, scalability, and ability to handle bilingual procedural data effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choice of Packages\n",
        "\n",
        "The following packages were selected to support the project’s technical requirements:\n",
        "- **langchain**: Facilitates document loading (`PyPDFLoader`), text splitting (`RecursiveCharacterTextSplitter`), and retrieval (`EnsembleRetriever`), streamlining data processing and search.\n",
        "- **fasttext**: Provides fast and accurate language detection for bilingual support.\n",
        "- **transformers**: Powers intent classification (`DistilBERT`) and LLM integration (`HuggingFaceEndpoint`), leveraging state-of-the-art NLP models.\n",
        "- **pdf2image** and **pytesseract**: Enable OCR for scanned PDFs, ensuring text extraction from non-text-based documents.\n",
        "- **spacy**: Supports NLP tasks like tokenization and entity recognition for intent classification and query expansion in both English and French.\n",
        "- **optuna**: Offers hyperparameter optimization for chunking and retrieval, improving system performance.\n",
        "- **sentence-transformers**: Computes cosine similarity for evaluating response quality, ensuring responses align with expected outputs.\n",
        "- **flask** and **waitress**: Provide a lightweight web framework and production-ready server for deploying the chatbot interface.\n",
        "- **pydantic**: Ensures structured data handling with robust models for procedures and responses, enhancing code reliability.\n",
        "\n",
        "These packages were chosen for their compatibility, performance, and community support, ensuring a robust and maintainable system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Business Understanding - Configuration and Utilities\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Business Understanding** phase in CRISP-DM sets the project's goals and foundation. For the bilingual procedure comparison chatbot, this phase defines the need to process English and French PDFs, handle user queries, and ensure a scalable, reliable system with performance evaluation.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell sets up the core infrastructure for the chatbot by initializing logging, defining file paths, creating data models, and providing utility functions for language detection and evaluation.\n",
        "\n",
        "### What the Code Does\n",
        "- **Logging**: Configures a log file (`procedure_comparison.log`) to track system events and errors.\n",
        "- **Paths**: Defines directories for English/French PDFs, test data, and evaluation results, plus paths for tools like Tesseract and Poppler.\n",
        "- **Data Models**: Uses Pydantic to create `Procedure` (for extracted PDF procedures) and `ChatbotResponse` (for query responses) models, ensuring structured data.\n",
        "- **Utility Functions**:\n",
        "  - `detect_language_from_prompt`: Identifies if a query is in English or French based on keywords, defaulting to English.\n",
        "  - `evaluate_intent_classification`: Calculates precision, recall, and F1-score for intent classification accuracy.\n",
        "  - `evaluate_response_quality`: Measures response quality using cosine similarity with `SentenceTransformer`.\n",
        "\n",
        "### Why It Matters\n",
        "This cell establishes the groundwork for a reliable, traceable system that supports bilingual processing and performance monitoring, enabling the chatbot to handle PDFs and queries effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional, Dict, Any\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    filename='procedure_comparison.log',\n",
        "    filemode='a',\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define paths\n",
        "BASE_DIR = Path('data').absolute()\n",
        "ENGLISH_DIR = BASE_DIR / 'english'\n",
        "FRENCH_DIR = BASE_DIR / 'french'\n",
        "TEST_DATA_DIR = BASE_DIR / 'test_data'\n",
        "EVAL_RESULTS_DIR = BASE_DIR / 'evaluation_results'\n",
        "POPPLER_PATH = r\"C:\\Users\\khalf\\Downloads\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin\"\n",
        "TESSERACT_PATH = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "TESSDATA_PREFIX = r\"C:\\Program Files\\Tesseract-OCR\\tessdata\"\n",
        "FASTTEXT_MODEL_PATH = r\"path/to/fasttext/model\"  # Update with actual path\n",
        "os.makedirs(EVAL_RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Pydantic models\n",
        "class Procedure(BaseModel):\n",
        "    id: int\n",
        "    title: str\n",
        "    section: str\n",
        "    steps: List[str]\n",
        "    responsible: str\n",
        "    source: str\n",
        "    filename: str\n",
        "    language: str\n",
        "\n",
        "class ChatbotResponse(BaseModel):\n",
        "    query: str\n",
        "    intent: str\n",
        "    response: str\n",
        "    language: str\n",
        "    procedure_name: Optional[str] = None\n",
        "    error: Optional[str] = None\n",
        "    analytics: Optional[Dict[str, Any]] = None\n",
        "\n",
        "# Utility functions\n",
        "def detect_language_from_prompt(text: str) -> str:\n",
        "    try:\n",
        "        if not isinstance(text, str) or not text.strip():\n",
        "            logger.warning(\"Invalid or empty text for language detection. Defaulting to 'en'.\")\n",
        "            return 'en'\n",
        "        text_lower = text.lower().strip()\n",
        "        if 'answer in french' in text_lower or 'répondez en français' in text_lower:\n",
        "            return 'fr'\n",
        "        if 'answer in english' in text_lower or 'répondez en anglais' in text_lower:\n",
        "            return 'en'\n",
        "        return 'en'  # Default to English if no instruction found\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Language detection failed: {str(e)}. Defaulting to 'en'.\")\n",
        "        return 'en'\n",
        "\n",
        "def evaluate_intent_classification(true_intents: List[str], predicted_intents: List[str]) -> Dict[str, float]:\n",
        "    try:\n",
        "        precision = precision_score(true_intents, predicted_intents, average='weighted', zero_division=0)\n",
        "        recall = recall_score(true_intents, predicted_intents, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(true_intents, predicted_intents, average='weighted', zero_division=0)\n",
        "        return {'precision': precision, 'recall': recall, 'f1_score': f1}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Intent classification evaluation error: {str(e)}\")\n",
        "        return {'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}\n",
        "\n",
        "def evaluate_response_quality(responses: List[str], expected_responses: List[str]) -> Dict[str, float]:\n",
        "    try:\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        response_embeddings = model.encode(responses)\n",
        "        expected_embeddings = model.encode(expected_responses)\n",
        "        similarities = [np.dot(r, e) / (np.linalg.norm(r) * np.linalg.norm(e))\n",
        "                        for r, e in zip(response_embeddings, expected_embeddings)]\n",
        "        return {\n",
        "            'avg_cosine_similarity': mean(similarities) if similarities else 0.0,\n",
        "            'std_cosine_similarity': np.std(similarities) if similarities else 0.0\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Response quality evaluation error: {str(e)}\")\n",
        "        return {'avg_cosine_similarity': 0.0, 'std_cosine_similarity': 0.0}\n",
        "\n",
        "logger.info(\"Business Understanding: Initialized logging, paths, models, and utilities.\")\n",
        "print(\"Configuration and utilities initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339a5449",
      "metadata": {},
      "source": [
        "# Phase 1: Business Understanding - Bilingual Prompt Templates\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Business Understanding** phase in CRISP-DM clarifies the project's goals, ensuring the bilingual procedure comparison chatbot delivers consistent, accurate, and user-tailored responses in English and French. This phase defines how the chatbot interacts with users by creating a single, flexible prompt template that dynamically handles any user intent and sentiment without relying on predefined intent lists, mappings, or keyword matching.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell defines bilingual (English and French) prompt templates using LangChain’s `PromptTemplate` and `FewShotPromptTemplate`. A single, general-purpose template supports dynamic intent and sentiment classification, processing queries based on inferred intents (via zero-shot classification) and sentiment (via transformer-based analysis). The template ensures seamless bilingual interaction, tailoring response tone to user sentiment (e.g., empathetic for negative, enthusiastic for positive).\n",
        "\n",
        "### What the Code Does\n",
        "- **Imports**: Uses `langchain.prompts` for `PromptTemplate` and `FewShotPromptTemplate` to create structured prompts.\n",
        "- **Example Prompt**: Defines a reusable `EXAMPLE_PROMPT` template for formatting query-response pairs.\n",
        "- **Bilingual Templates**: Creates a dictionary (`PROMPT_TEMPLATES`) with a single `general` template for each language (English and French):\n",
        "  - **General Template**: Handles all intents and sentiments dynamically by instructing the LLM to interpret intent and sentiment from the query and context, using `metadata_index` for procedure-specific information and chat history for context.\n",
        "  - **Structure**: Includes:\n",
        "    - **Examples**: Sample query-response pairs for various intents (e.g., listing, questioning, comparing) and sentiments (e.g., positive, negative, neutral) to guide the LLM.\n",
        "    - **Prefix**: Provides instructions for the chatbot, context, chat history, inferred intent, and sentiment-driven tone.\n",
        "    - **Suffix**: Standardizes the response start (e.g., “Answer: ” or “Réponse: ”).\n",
        "    - **Input Variables**: Supports dynamic inputs like `context`, `chat_history`, `question`, `procedure_name`, `intent`, and `sentiment`.\n",
        "- **Logging**: Logs template initialization and prints a confirmation message.\n",
        "\n",
        "### Why It Matters\n",
        "The single, flexible prompt template ensures consistent, language-appropriate, and sentiment-tailored responses for any user intent, eliminating the need for predefined intent or sentiment categories. This supports dynamic intent and sentiment classification using zero-shot and transformer-based methods, enabling the chatbot to handle diverse and novel queries with an adaptive tone while processing procedural data from PDFs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4bd2818",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "# Bilingual prompt templates\n",
        "EXAMPLE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"query\", \"response\"],\n",
        "    template=\"Query: {query}\\nResponse: {response}\"\n",
        ")\n",
        "\n",
        "PROMPT_TEMPLATES = {\n",
        "    'en': {\n",
        "        'general': {\n",
        "            'general': FewShotPromptTemplate(\n",
        "                examples=[\n",
        "                    {\"query\": \"List all procedures\", \"response\": \"I'm excited to help! Here are the procedures: 1. Sample Procedure\\n2. Test Procedure\"},\n",
        "                    {\"query\": \"What is the purpose of Sample Procedure?\", \"response\": \"Great question! The purpose of Sample Procedure is to demonstrate the chatbot.\"},\n",
        "                    {\"query\": \"Details of Sample Procedure\", \"response\": \"Happy to provide details! **Procedure**: Sample Procedure\\n**Purpose**: Demonstrate chatbot\\n**Steps**:\\n1. Start process\\n2. Complete task\\n**Responsible**:\\n- Not specified\"},\n",
        "                    {\"query\": \"I'm frustrated, why is Sample Procedure so unclear?\", \"response\": \"I'm sorry to hear you're frustrated. Let me clarify: Sample Procedure aims to demonstrate the chatbot with steps like starting the process and completing the task. Can I assist further?\"},\n",
        "                    {\"query\": \"Compare Sample Procedure in English and French\", \"response\": \"I'm thrilled to compare for you! | Aspect | English | French |\\n|--------|---------|--------|\\n| Purpose | Demonstrate chatbot | Démontrer le chatbot |\\n| Steps | 2 | 2 |\"},\n",
        "                    {\"query\": \"Tell me about the system\", \"response\": \"Glad you're curious! The system is a bilingual chatbot designed to process and compare procedural documents in English and French.\"}\n",
        "                ],\n",
        "                example_prompt=EXAMPLE_PROMPT,\n",
        "                prefix=\"\"\"You are an advanced bilingual chatbot. Process the query in English based on the inferred intent: '{intent}' and sentiment: '{sentiment}'.\n",
        "Provide a clear, accurate, and concise response using the provided context and chat history.\n",
        "Adjust the tone based on sentiment: empathetic and supportive for negative, enthusiastic for positive, neutral for neutral.\n",
        "If no procedure is found, respond: \"No procedure found.\"\n",
        "Context: {context}\n",
        "Chat History: {chat_history}\n",
        "Question: {question}\n",
        "Procedure Name (if applicable): {procedure_name}\n",
        "\"\"\",\n",
        "                suffix=\"Answer: \",\n",
        "                input_variables=[\"context\", \"chat_history\", \"question\", \"intent\", \"sentiment\", \"procedure_name\"]\n",
        "            )\n",
        "        }\n",
        "    },\n",
        "    'fr': {\n",
        "        'general': {\n",
        "            'general': FewShotPromptTemplate(\n",
        "                examples=[\n",
        "                    {\"query\": \"Liste toutes les procédures\", \"response\": \"Je suis ravi de vous aider ! Voici les procédures : 1. Procédure Exemple\\n2. Procédure Test\"},\n",
        "                    {\"query\": \"Quel est le but de la Procédure Exemple ?\", \"response\": \"Excellente question ! Le but de la Procédure Exemple est de démontrer le chatbot.\"},\n",
        "                    {\"query\": \"Détails de la Procédure Exemple\", \"response\": \"Heureux de fournir des détails ! **Procédure** : Procédure Exemple\\n**Objectif** : Démontrer le chatbot\\n**Étapes** :\\n1. Démarrer le processus\\n2. Compléter la tâche\\n**Responsable** :\\n- Non spécifié\"},\n",
        "                    {\"query\": \"Je suis agacé, pourquoi la Procédure Exemple est-elle si vague ?\", \"response\": \"Je suis désolé que vous soyez agacé. Permettez-moi de clarifier : la Procédure Exemple vise à démontrer le chatbot avec des étapes comme démarrer le processus et compléter la tâche. Puis-je vous aider davantage ?\"},\n",
        "                    {\"query\": \"Comparez la Procédure Exemple en anglais et français\", \"response\": \"Ravi de comparer pour vous ! | Aspect | Anglais | Français |\\n|--------|---------|----------|\\n| Objectif | Démontrer le chatbot | Démontrer le chatbot |\\n| Étapes | 2 | 2 |\"},\n",
        "                    {\"query\": \"Parlez-moi du système\", \"response\": \"Content que vous soyez curieux ! Le système est un chatbot bilingue conçu pour traiter et comparer des documents procéduraux en anglais et français.\"}\n",
        "                ],\n",
        "                example_prompt=EXAMPLE_PROMPT,\n",
        "                prefix=\"\"\"Vous êtes un chatbot bilingue avancé. Traitez la requête en français en fonction de l'intention déduite : '{intent}' et du sentiment : '{sentiment}'.\n",
        "Fournissez une réponse claire, précise et concise en utilisant le contexte et l'historique de conversation fournis.\n",
        "Adaptez le ton selon le sentiment : empathique et soutenant pour négatif, enthousiaste pour positif, neutre pour neutre.\n",
        "Si aucune procédure n'est trouvée, répondez : \"Aucune procédure trouvée.\"\n",
        "Contexte : {context}\n",
        "Historique : {chat_history}\n",
        "Question : {question}\n",
        "Nom de la procédure (si applicable) : {procedure_name}\n",
        "\"\"\",\n",
        "                suffix=\"Réponse : \",\n",
        "                input_variables=[\"context\", \"chat_history\", \"question\", \"intent\", \"sentiment\", \"procedure_name\"]\n",
        "            )\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "logger.info(\"Business Understanding: Defined bilingual prompt templates with sentiment support.\")\n",
        "print(\"Bilingual prompt templates with sentiment support defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ffe58f",
      "metadata": {},
      "source": [
        "# Phase 2: Data Understanding - Explore Directories\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Data Understanding** phase in CRISP-DM focuses on exploring and assessing the available data to ensure it meets the project's needs. For the bilingual procedure comparison chatbot, this phase verifies the presence and organization of PDF files in English and French directories, confirming the data foundation for procedure extraction.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell defines a function to check and list PDF files in the `data/english` and `data/french` directories, ensuring the chatbot has access to the necessary documents. It logs and displays the results for transparency and debugging.\n",
        "\n",
        "### What the Code Does\n",
        "- **Directory Check**: Verifies that the `ENGLISH_DIR` and `FRENCH_DIR` (defined earlier) exist, raising a `FileNotFoundError` if either is missing.\n",
        "- **File Collection**: Gathers and sorts all `.pdf` files from both directories using `pathlib.Path.iterdir()` and filters by file extension.\n",
        "- **Logging**: Logs the number of files and their paths in both directories to `procedure_comparison.log` for traceability.\n",
        "- **Output**: Prints the count and names of PDF files in each directory for user visibility.\n",
        "- **Return**: Returns lists of English and French PDF file paths for use in subsequent phases.\n",
        "\n",
        "### Why It Matters\n",
        "This function ensures the chatbot’s data sources (PDFs) are accessible and properly organized before processing. By logging and displaying file details, it aids debugging and confirms the data is ready for extraction, supporting the project’s goal of processing bilingual procedural documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5054fa97",
      "metadata": {},
      "outputs": [],
      "source": [
        "def explore_directories():\n",
        "    if not ENGLISH_DIR.exists():\n",
        "        logger.error(f\"English directory missing: {ENGLISH_DIR}\")\n",
        "        raise FileNotFoundError(\"English directory not found\")\n",
        "    if not FRENCH_DIR.exists():\n",
        "        logger.error(f\"French directory missing: {FRENCH_DIR}\")\n",
        "        raise FileNotFoundError(\"French directory not found\")\n",
        "\n",
        "    english_files = sorted({f for f in ENGLISH_DIR.iterdir() if f.is_file() and f.suffix.lower() == '.pdf'})\n",
        "    french_files = sorted({f for f in FRENCH_DIR.iterdir() if f.is_file() and f.suffix.lower() == '.pdf'})\n",
        "\n",
        "    logger.info(f\"English directory ({ENGLISH_DIR}): {len(english_files)} files found: {[str(f) for f in english_files]}\")\n",
        "    logger.info(f\"French directory ({FRENCH_DIR}): {len(french_files)} files found: {[str(f) for f in french_files]}\")\n",
        "\n",
        "    print(f\"English PDFs: {len(english_files)}\")\n",
        "    for f in english_files:\n",
        "        print(f\" - {f.name}\")\n",
        "    print(f\"French PDFs: {len(french_files)}\")\n",
        "    for f in french_files:\n",
        "        print(f\" - {f.name}\")\n",
        "\n",
        "    return english_files, french_files\n",
        "\n",
        "english_files, french_files = explore_directories()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a47be96",
      "metadata": {},
      "source": [
        "# Phase 3: Data Preparation - Parameter Optimizer\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Data Preparation** phase in CRISP-DM focuses on transforming raw data into a suitable format for modeling. For the bilingual procedure comparison chatbot, this phase optimizes text chunking parameters to ensure efficient document processing, enhancing the chatbot's ability to extract and query procedural information from PDFs.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell defines the `ParameterOptimizer` class, which optimizes chunk size and overlap for splitting PDF text into manageable pieces for retrieval and processing. It uses document structure analysis and embeddings to tailor parameters, ensuring accurate and efficient handling of bilingual (English and French) documents.\n",
        "\n",
        "### What the Code Does\n",
        "- **Imports**: Includes libraries for JSON handling (`json`), NLP (`spacy`), embeddings (`HuggingFaceEmbeddings`), clustering (`hdbscan`), and statistical analysis (`statistics`).\n",
        "- **ParameterOptimizer Class**:\n",
        "  - **Initialization**: Sets up embeddings, a parameter cache, performance history, and a JSON file (`parameters.json`) for storing optimized parameters.\n",
        "  - **`load_parameters`**: Loads cached parameters from `parameters.json` if available, logging success or errors.\n",
        "  - **`save_parameters`**: Saves optimized parameters to `parameters.json` for reuse, with error handling.\n",
        "  - **`analyze_document_structure`**: Analyzes text using `spacy` (English or French models) to extract sentences, paragraphs, headings, and list items, returning metrics like average sentence/paragraph length, heading frequency, and list density.\n",
        "  - **`optimize_chunk_params`**: Determines optimal chunk size and overlap based on document length, language, structure (e.g., sentence length, heading frequency), and clustering of sentence embeddings using `hdbscan`. Returns defaults (1000, 200) on errors or empty text.\n",
        "  - **`get_optimized_params`**: Retrieves or computes chunking parameters, caching results to avoid redundant processing.\n",
        "- **Logging and Output**: Logs and prints confirmation of `ParameterOptimizer` initialization.\n",
        "\n",
        "### Why It Matters\n",
        "The `ParameterOptimizer` ensures text is split into chunks that balance context preservation and processing efficiency, critical for accurate retrieval in the chatbot’s RAG pipeline. By tailoring chunking to document structure and language, it enhances the quality of procedure extraction and query responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "defc14a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import spacy\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "import hdbscan\n",
        "from statistics import mean, median\n",
        "\n",
        "class ParameterOptimizer:\n",
        "    def __init__(self, embeddings: HuggingFaceEmbeddings):\n",
        "        self.embeddings = embeddings\n",
        "        self.parameter_cache = {}\n",
        "        self.performance_history = []\n",
        "        self.parameter_file = 'parameters.json'\n",
        "        self.load_parameters()\n",
        "\n",
        "    def load_parameters(self):\n",
        "        try:\n",
        "            if os.path.exists(self.parameter_file):\n",
        "                with open(self.parameter_file, 'r') as f:\n",
        "                    self.parameter_cache = json.load(f)\n",
        "                logger.info(\"Loaded parameters from parameters.json\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load parameters: {str(e)}\")\n",
        "\n",
        "    def save_parameters(self):\n",
        "        try:\n",
        "            with open(self.parameter_file, 'w') as f:\n",
        "                json.dump(self.parameter_cache, f, indent=2)\n",
        "            logger.info(\"Saved parameters to parameters.json\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to save parameters: {str(e)}\")\n",
        "\n",
        "    def analyze_document_structure(self, text: str, language: str) -> dict:\n",
        "        try:\n",
        "            nlp = spacy.load('en_core_web_sm', disable=['ner']) if language == 'en' else spacy.load('fr_core_news_sm', disable=['ner'])\n",
        "            doc = nlp(text[:15000])\n",
        "            sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "            sentence_lengths = [len(sent) for sent in sentences]\n",
        "            paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
        "            paragraph_lengths = [len(p) for p in paragraphs]\n",
        "            heading_pattern = r'^(?:[A-Z][\\w\\s\\-:]{5,50}(?:\\n|$)|(?:Section|Chapitre|Part|Partie)\\s*\\d+[\\:\\-\\.]?\\s*.+?(?:\\n|$))'\n",
        "            headings = [m.group(0).strip() for m in re.finditer(heading_pattern, text, re.MULTILINE)]\n",
        "            heading_freq = len(headings) / (len(text) / 1000) if len(text) > 0 else 0\n",
        "            list_pattern = r'^(?:\\d+\\.|\\d+[\\-\\:]|[a-zA-Z]\\.|[\\-\\*\\+>·◦•✓✔]|[IVXLCDM]+\\.)\\s*(.*?)(?:\\n|$)' \n",
        "            list_items = [m.group(0).strip() for m in re.finditer(list_pattern, text, re.MULTILINE)]\n",
        "            list_density = len(list_items) / len(sentences) if sentences else 0\n",
        "            return {\n",
        "                'sentences': sentences,\n",
        "                'sentence_lengths': sentence_lengths,\n",
        "                'avg_sentence_length': mean(sentence_lengths) if sentence_lengths else 100,\n",
        "                'median_sentence_length': median(sentence_lengths) if sentence_lengths else 100,\n",
        "                'paragraphs': paragraphs,\n",
        "                'avg_paragraph_length': mean(paragraph_lengths) if paragraph_lengths else 500,\n",
        "                'heading_freq': heading_freq,\n",
        "                'list_density': list_density\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Document structure analysis failed: {str(e)}. Using defaults.\")\n",
        "            return {\n",
        "                'sentences': [],\n",
        "                'sentence_lengths': [],\n",
        "                'avg_sentence_length': 100,\n",
        "                'median_sentence_length': 100,\n",
        "                'paragraphs': [],\n",
        "                'avg_paragraph_length': 500,\n",
        "                'heading_freq': 0,\n",
        "                'list_density': 0\n",
        "            }\n",
        "\n",
        "    def optimize_chunk_params(self, text: str) -> tuple[int, int]:\n",
        "        try:\n",
        "            if not text.strip():\n",
        "                logger.warning(\"Empty text provided. Using default params.\")\n",
        "                return 1000, 200\n",
        "            language = detect_language_from_prompt(text)\n",
        "            doc_length = len(text)\n",
        "            structure = self.analyze_document_structure(text, language)\n",
        "            sentences = structure['sentences']\n",
        "            avg_sentence_length = structure['avg_sentence_length']\n",
        "            median_sentence_length = structure['median_sentence_length']\n",
        "            avg_paragraph_length = structure['avg_paragraph_length']\n",
        "            heading_freq = structure['heading_freq']\n",
        "            list_density = structure['list_density']\n",
        "            if len(sentences) < 3:\n",
        "                logger.info(\"Too few sentences for clustering. Using structure-based params.\")\n",
        "                chunk_size = min(max(int(avg_paragraph_length), 250), 2000)\n",
        "                chunk_overlap = min(int(chunk_size * 0.2) + (50 if language == 'fr' else 0), chunk_size // 2)\n",
        "                return chunk_size, chunk_overlap\n",
        "            sentence_embeddings = self.embeddings.embed_documents(sentences)\n",
        "            if not sentence_embeddings:\n",
        "                logger.warning(\"Failed to generate embeddings. Using structure-based params.\")\n",
        "                chunk_size = min(max(int(avg_paragraph_length), 250), 2000)\n",
        "                chunk_overlap = min(int(chunk_size * 0.2) + (50 if language == 'fr' else 0), chunk_size // 2)\n",
        "                return chunk_size, chunk_overlap\n",
        "            clusterer = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=2, cluster_selection_method='eom')\n",
        "            cluster_labels = clusterer.fit_predict(sentence_embeddings)\n",
        "            unique_clusters = set(cluster_labels) - {-1}\n",
        "            n_clusters = len(unique_clusters)\n",
        "            cluster_sizes = [sum(cluster_labels == c) for c in unique_clusters]\n",
        "            largest_cluster_size = max(cluster_sizes) if cluster_sizes else len(sentences)\n",
        "            cluster_density = largest_cluster_size / len(sentences) if sentences else 0.1\n",
        "            if unique_clusters:\n",
        "                largest_cluster = np.argmax(cluster_sizes)\n",
        "                cluster_indices = [i for i, c in enumerate(cluster_labels) if c == largest_cluster]\n",
        "                if len(cluster_indices) > 1:\n",
        "                    cluster_embeddings = [sentence_embeddings[i] for i in cluster_indices]\n",
        "                    distances = [\n",
        "                        np.linalg.norm(np.array(cluster_embeddings[i]) - np.array(cluster_embeddings[i+1]))\n",
        "                        for i in range(len(cluster_embeddings)-1)\n",
        "                    ]\n",
        "                    avg_embedding_distance = mean(distances) if distances else 0.5\n",
        "                else:\n",
        "                    avg_embedding_distance = 0.5\n",
        "            else:\n",
        "                avg_embedding_distance = 0.5\n",
        "            chunk_sizes = [250, 500, 750, 1000, 1250, 1500, 2000]\n",
        "            if list_density > 0.5 or heading_freq > 0.5:\n",
        "                chunk_size = chunk_sizes[0] if avg_sentence_length < 75 else chunk_sizes[1]\n",
        "            elif avg_paragraph_length < 500 or n_clusters > 3:\n",
        "                chunk_size = chunk_sizes[2] if avg_sentence_length < 150 else chunk_sizes[3]\n",
        "            else:\n",
        "                chunk_size = chunk_sizes[4] if avg_sentence_length < 200 else chunk_sizes[5 if avg_sentence_length < 300 else 6]\n",
        "            if doc_length < 1500:\n",
        "                chunk_size = min(chunk_size, 500)\n",
        "            elif doc_length > 15000:\n",
        "                chunk_size = max(chunk_size, 1000)\n",
        "            base_overlap = 100 if cluster_density < 0.5 else 150\n",
        "            if avg_embedding_distance > 0.7:\n",
        "                base_overlap += 50\n",
        "            if heading_freq > 0.5:\n",
        "                base_overlap = min(base_overlap, 100)\n",
        "            if language == 'fr':\n",
        "                base_overlap += 50\n",
        "            chunk_overlap = min(base_overlap, chunk_size // 2)\n",
        "            logger.debug(\n",
        "                f\"Chunk params: size={chunk_size}, overlap={chunk_overlap}, \"\n",
        "                f\"doc_length={doc_length}, n_clusters={n_clusters}, \"\n",
        "                f\"avg_sentence_length={avg_sentence_length:.2f}, \"\n",
        "                f\"median_sentence_length={median_sentence_length:.2f}, \"\n",
        "                f\"avg_paragraph_length={avg_paragraph_length:.2f}, \"\n",
        "                f\"heading_freq={heading_freq:.2f}, list_density={list_density:.2f}, \"\n",
        "                f\"cluster_density={cluster_density:.2f}, \"\n",
        "                f\"avg_embedding_distance={avg_embedding_distance:.2f}, language={language}\"\n",
        "            )\n",
        "            return chunk_size, chunk_overlap\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in optimize_chunk_params: {str(e)}. Returning default parameters.\")\n",
        "            return 1000, 200  # Default chunk size and overlap\n",
        "    def get_optimized_params(self, param_type: str, input_data: Any) -> Any:\n",
        "        cache_key = f\"{param_type}_{hash(str(input_data))}\"\n",
        "        if cache_key in self.parameter_cache:\n",
        "            logger.debug(f\"Using cached params for {cache_key}: {self.parameter_cache[cache_key]}\")\n",
        "            return self.parameter_cache[cache_key]\n",
        "        if param_type == 'chunk':\n",
        "            best_params = self.optimize_chunk_params(input_data)\n",
        "            self.parameter_cache[cache_key] = best_params\n",
        "            self.performance_history.append({'param_type': param_type, 'objective': None})\n",
        "            self.save_parameters()\n",
        "            return best_params\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown parameter type: {param_type}\")\n",
        "\n",
        "logger.info(\"Data Preparation: Initialized ParameterOptimizer.\")\n",
        "print(\"ParameterOptimizer initialized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acdf2513",
      "metadata": {},
      "source": [
        "# Phase 3: Data Preparation - PDF Processor\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Data Preparation** phase in CRISP-DM transforms raw data into a usable format for modeling. For the bilingual procedure comparison chatbot, this phase processes PDF documents in English and French to extract procedures and store them for efficient retrieval, enabling the chatbot to query and compare procedural information.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell defines the `PDFProcessor` class, which extracts text from PDFs (using direct text extraction or OCR for scanned documents), identifies procedures, and stores them in `Chroma` (for semantic search) and `BM25` (for keyword search) for hybrid retrieval. It ensures robust handling of bilingual documents.\n",
        "\n",
        "### What the Code Does\n",
        "- **Imports**: Includes libraries for JSON handling (`json`), text processing (`re`, `spacy`), async I/O (`aiofiles`, `asyncio`), PDF processing (`PyPDFLoader`, `pdf2image`, `pytesseract`), embeddings (`HuggingFaceEmbeddings`), and document storage (`Chroma`).\n",
        "- **PDFProcessor Class**:\n",
        "  - **Initialization**: Sets up Tesseract OCR, `spacy` models (English/French), embeddings (`all-MiniLM-L6-v2`), `Chroma` vectorstore, `BM25` document list, and a `ParameterOptimizer` instance. Validates tool paths and logs initialization.\n",
        "  - **`optimize_chunk_size`**: Uses `ParameterOptimizer` to determine optimal text chunk size and overlap for splitting documents.\n",
        "  - **`infer_document_type`**: Analyzes text structure (using regex and clustering) to classify documents as list-heavy, long-text, or generic, aiding procedure extraction.\n",
        "  - **`preprocess_image`**: Enhances PDF images for OCR using OpenCV (grayscale, thresholding).\n",
        "  - **`extract_text_with_ocr`**: Converts PDFs to images and extracts text using Tesseract, supporting English/French.\n",
        "  - **`extract_procedures`**: Identifies procedures in text using regex patterns for lists or sections, creating `Procedure` objects with metadata.\n",
        "  - **`process_pdf`**: Extracts text from a PDF (via `PyPDFLoader` or OCR fallback), splits it into chunks, extracts procedures, and stores them in `Chroma` and `BM25` with metadata.\n",
        "  - **`process_all_pdfs`**: Asynchronously processes multiple PDFs, handling errors and logging results.\n",
        "- **Logging and Output**: Logs and prints initialization and processing outcomes for traceability.\n",
        "\n",
        "### Why It Matters\n",
        "The `PDFProcessor` ensures that PDF content is accurately extracted, structured, and stored for retrieval, supporting the chatbot’s ability to handle bilingual queries. Its hybrid storage approach (`Chroma` + `BM25`) and robust error handling make it efficient and reliable for processing diverse document types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4918f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import uuid\n",
        "import re\n",
        "import spacy\n",
        "import aiofiles\n",
        "import asyncio\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.schema import Document\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class PDFProcessor:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH\n",
        "            if not os.path.exists(TESSERACT_PATH):\n",
        "                raise FileNotFoundError(f\"Tesseract executable not found at: {TESSERACT_PATH}\")\n",
        "            if not os.path.exists(TESSDATA_PREFIX):\n",
        "                raise FileNotFoundError(f\"Tessdata directory not found at: {TESSDATA_PREFIX}\")\n",
        "            os.environ['TESSDATA_PREFIX'] = TESSDATA_PREFIX\n",
        "            self.nlp_en = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "            self.nlp_fr = spacy.load('fr_core_news_sm', disable=['ner'])\n",
        "            self.embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
        "            self.vectorstore = Chroma(collection_name='procedures', embedding_function=self.embeddings)\n",
        "            self.bm25_docs = []\n",
        "            self.metadata_index = {}\n",
        "            self.performance_metrics = {'chunk_sizes': [], 'retrieval_scores': [], 'latencies': []}\n",
        "            self.query_cache = {}\n",
        "            self.optimizer = ParameterOptimizer(self.embeddings)\n",
        "            self.text_splitter = None\n",
        "            if not os.path.exists(POPPLER_PATH):\n",
        "                raise FileNotFoundError(f\"Poppler path does not exist: {POPPLER_PATH}\")\n",
        "            logger.info(\"PDFProcessor initialized successfully.\")\n",
        "            print(\"PDFProcessor initialized successfully.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"PDFProcessor init error: {str(e)}\")\n",
        "            raise ValueError(f\"Failed to initialize PDFProcessor: {str(e)}\")\n",
        "\n",
        "    def optimize_chunk_size(self, text: str) -> tuple[int, float]:\n",
        "        chunk_size, chunk_overlap = self.optimizer.get_optimized_params('chunk', text)\n",
        "        self.performance_metrics['chunk_sizes'].append(chunk_size)\n",
        "        logger.info(f\"Optimized chunk_size: {chunk_size}, chunk_overlap: {chunk_overlap}\")\n",
        "        return chunk_size, chunk_overlap\n",
        "\n",
        "    def infer_document_type(self, text: str) -> str:\n",
        "        try:\n",
        "            language = detect_language_from_prompt(text)\n",
        "            nlp = self.nlp_en if language == 'en' else self.nlp_fr\n",
        "            section_pattern = r'^(?:Functioning|Fonctionnement)\\s*[:\\-]?\\s*(.*?)(?=\\n\\n|\\n|$|\\s{2,})'\n",
        "            if re.search(section_pattern, text, re.I | re.M):\n",
        "                logger.info(\"Found 'functioning' or 'fonctionnement' section. Type: procedure\")\n",
        "                return 'procedure'\n",
        "            structure = self.optimizer.analyze_document_structure(text, language)\n",
        "            sentences = structure['sentences']\n",
        "            list_density = structure['list_density']\n",
        "            heading_freq = structure['heading_freq']\n",
        "            avg_paragraph_length = structure['avg_paragraph_length']\n",
        "            avg_sentence_length = structure['avg_sentence_length']\n",
        "            sentence_embeddings = self.embeddings.embed_documents(sentences) if sentences else []\n",
        "            if not sentence_embeddings or len(sentences) < 3:\n",
        "                logger.info(\"Insufficient sentences for clustering. Using structure-based inference.\")\n",
        "                if list_density > 0.5:\n",
        "                    return f'type_list_heavy_{int(list_density * 100)}'\n",
        "                elif avg_paragraph_length > 500:\n",
        "                    return f'type_long_text_{int(avg_paragraph_length // 100)}'\n",
        "                return f'type_generic_{int(avg_sentence_length // 50)}'\n",
        "            features = []\n",
        "            for i, sent in enumerate(sentences):\n",
        "                sent_features = [\n",
        "                    len(sent) / 1000.0,\n",
        "                    list_density,\n",
        "                    heading_freq,\n",
        "                    avg_paragraph_length / 1000.0,\n",
        "                    1 if re.match(r'^(?:\\d+\\.|[-*+>·◦•✓✔]|\\d+[\\-\\:]|[a-zA-Z]\\.|[IVXLCDM]+\\.)', sent) else 0\n",
        "                ]\n",
        "                features.append(sent_features + sentence_embeddings[i])\n",
        "            clusterer = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=2, cluster_selection_method='eom')\n",
        "            cluster_labels = clusterer.fit_predict(features)\n",
        "            unique_clusters = set(cluster_labels) - {-1}\n",
        "            if not unique_clusters:\n",
        "                logger.info(\"No clusters formed. Using structure-based inference.\")\n",
        "                if list_density > 0.5:\n",
        "                    return f'type_list_heavy_{int(list_density * 100)}'\n",
        "                elif avg_paragraph_length > 500:\n",
        "                    return f'type_long_text_{int(avg_paragraph_length // 100)}'\n",
        "                return f'type_generic_{int(avg_sentence_length // 50)}'\n",
        "            cluster_properties = []\n",
        "            for c in unique_clusters:\n",
        "                cluster_indices = [i for i, label in enumerate(cluster_labels) if label == c]\n",
        "                cluster_sentences = [sentences[i] for i in cluster_indices]\n",
        "                cluster_list_density = sum(1 for s in cluster_sentences if re.match(r'^(?:\\d+\\.|[-*+>·◦•✓✔]|\\d+[\\-\\:]|[a-zA-Z]\\.|[IVXLCDM]+\\.)', s)) / len(cluster_sentences) if cluster_sentences else 0\n",
        "                cluster_headings = sum(1 for s in cluster_sentences if re.match(r'^[A-Z][\\w\\s\\-:]{5,50}(?:\\n|$)', s)) / len(cluster_sentences) if cluster_sentences else 0\n",
        "                cluster_avg_length = mean([len(s) for s in cluster_sentences]) if cluster_sentences else avg_sentence_length\n",
        "                cluster_properties.append({\n",
        "                    'size': len(cluster_indices),\n",
        "                    'list_density': cluster_list_density,\n",
        "                    'heading_density': cluster_headings,\n",
        "                    'avg_sentence_length': cluster_avg_length\n",
        "                })\n",
        "            max_cluster = max(cluster_properties, key=lambda x: x['size']) if cluster_properties else {'list_density': 0, 'avg_sentence_length': avg_sentence_length}\n",
        "            if max_cluster['list_density'] > 0.5:\n",
        "                return f'type_list_heavy_{int(max_cluster['list_density'] * 100)}'\n",
        "            elif max_cluster['avg_sentence_length'] > 200:\n",
        "                return f'type_long_text_{int(max_cluster['avg_sentence_length'] // 50)}'\n",
        "            return f'type_generic_{int(max_cluster['avg_sentence_length'] // 50)}'\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Document type inference error: {str(e)}\")\n",
        "            return 'type_generic_100'\n",
        "\n",
        "    async def preprocess_image(self, image: Image.Image) -> Image.Image:\n",
        "        try:\n",
        "            img_array = np.array(image)\n",
        "            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "            return Image.fromarray(thresh)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Image preprocessing error: {str(e)}\")\n",
        "            return image\n",
        "\n",
        "    async def extract_text_with_ocr(self, file_path: str) -> str:\n",
        "        try:\n",
        "            images = pdf2image.convert_from_path(file_path, poppler_path=POPPLER_PATH)\n",
        "            text = ''\n",
        "            for img in images:\n",
        "                processed_img = await self.preprocess_image(img)\n",
        "                language = detect_language_from_prompt(text[:1000]) if text else 'en'\n",
        "                text += pytesseract.image_to_string(processed_img, lang='eng' if language == 'en' else 'fra') + '\\n'\n",
        "            return text.strip()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"OCR extraction error for {file_path}: {str(e)}\")\n",
        "            return ''\n",
        "\n",
        "    def extract_procedures(self, text: str, filename: str, language: str) -> List[Procedure]:\n",
        "        try:\n",
        "            doc_type = self.infer_document_type(text)\n",
        "            procedures = []\n",
        "            if doc_type.startswith('type_list_heavy'):\n",
        "                pattern = r'^(\\d+\\.|[-*+>·◦•✓✔]|[a-zA-Z]\\.|[IVXLCDM]+\\.)\\s*(.*?)(?=\\n(?:\\d+\\.|[-*+>·◦•✓✔]|[a-zA-Z]\\.|[IVXLCDM]+\\.)|\\n\\n|$)' \n",
        "                matches = re.finditer(pattern, text, re.MULTILINE | re.DOTALL)\n",
        "                for i, match in enumerate(matches):\n",
        "                    step_text = match.group(2).strip()\n",
        "                    procedures.append(Procedure(\n",
        "                        id=i,\n",
        "                        title=f\"Procedure {i+1}\",\n",
        "                        section='Unknown',\n",
        "                        steps=[step_text],\n",
        "                        responsible='Unknown',\n",
        "                        source=filename,\n",
        "                        filename=filename,\n",
        "                        language=language\n",
        "                    ))\n",
        "            else:\n",
        "                pattern = r'(?:(?:Section|Chapitre|Procedure|Procédure)\\s*\\d+[\\:\\-\\.]?\\s*(.*?)(?=\\n\\n|\\n|$|\\s{2,}))'\n",
        "                matches = re.finditer(pattern, text, re.MULTILINE | re.DOTALL)\n",
        "                for i, match in enumerate(matches):\n",
        "                    section = match.group(1).strip()\n",
        "                    procedures.append(Procedure(\n",
        "                        id=i,\n",
        "                        title=section,\n",
        "                        section=section,\n",
        "                        steps=['Unknown'],\n",
        "                        responsible='Unknown',\n",
        "                        source=filename,\n",
        "                        filename=filename,\n",
        "                        language=language\n",
        "                    ))\n",
        "            return procedures\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Procedure extraction error: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    async def process_pdf(self, file_path: Path) -> List[Document]:\n",
        "        try:\n",
        "            loader = PyPDFLoader(str(file_path))\n",
        "            text = ''\n",
        "            try:\n",
        "                pages = loader.load()\n",
        "                text = '\\n'.join(page.page_content for page in pages)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"PyPDFLoader failed for {file_path}: {str(e)}. Falling back to OCR.\")\n",
        "                text = await self.extract_text_with_ocr(str(file_path))\n",
        "            if not text.strip():\n",
        "                logger.warning(f\"No text extracted from {file_path}\")\n",
        "                return []\n",
        "            language = detect_language_from_prompt(text[:1000])\n",
        "            chunk_size, chunk_overlap = self.optimize_chunk_size(text)\n",
        "            self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=chunk_size,\n",
        "                chunk_overlap=chunk_overlap,\n",
        "                length_function=len\n",
        "            )\n",
        "            chunks = self.text_splitter.split_text(text)\n",
        "            documents = [\n",
        "                Document(page_content=chunk, metadata={'source': str(file_path), 'language': language})\n",
        "                for chunk in chunks\n",
        "            ]\n",
        "            procedures = self.extract_procedures(text, file_path.name, language)\n",
        "            for proc in procedures:\n",
        "                proc_id = str(uuid.uuid4())\n",
        "                self.metadata_index[proc_id] = proc.dict()\n",
        "                documents.append(Document(\n",
        "                    page_content='\\n'.join(proc.steps),\n",
        "                    metadata={'source': proc.source, 'language': proc.language, 'procedure_id': proc_id}\n",
        "                ))\n",
        "            self.vectorstore.add_documents(documents)\n",
        "            self.bm25_docs.extend([doc.page_content for doc in documents])\n",
        "            logger.info(f\"Processed {file_path}: {len(documents)} documents added\")\n",
        "            return documents\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing {file_path}: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    async def process_all_pdfs(self, english_files: List[Path], french_files: List[Path]):\n",
        "        tasks = [self.process_pdf(file) for file in english_files + french_files]\n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "        for file, result in zip(english_files + french_files, results):\n",
        "            if isinstance(result, Exception):\n",
        "                logger.error(f\"Failed to process {file}: {str(result)}\")\n",
        "            else:\n",
        "                logger.info(f\"Successfully processed {file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63211a2a",
      "metadata": {},
      "source": [
        "# Phase 4: Modeling - Query Handler\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Modeling** phase in CRISP-DM focuses on building and applying models to achieve project goals. For the bilingual procedure comparison chatbot, this phase implements the `QueryHandler` class to process user queries using Retrieval-Augmented Generation (RAG), fully dynamic intent classification, and sentiment analysis, enabling accurate, context-aware, and user-tailored responses in English and French without predefined intent lists, mappings, or keyword matching.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell defines the `QueryHandler` class, which handles user queries by classifying their intent dynamically using zero-shot classification (`facebook/bart-large-mnli`), analyzing sentiment using a transformer-based model (`distilbert-base-uncased-finetuned-sst-2-english`), retrieving relevant documents, and generating responses using a large language model (LLM). It optimizes retrieval and LLM parameters to ensure efficient and accurate query processing, with intent and sentiment classification driven by query content and `metadata_index`.\n",
        "\n",
        "### What the Code Does\n",
        "- **Imports**: Includes libraries for regex (`re`), timing (`time`), async processing (`asyncio`), NLP (`spacy`), retrieval (`Chroma`, `BM25Retriever`, `EnsembleRetriever`), sentiment analysis (`transformers.pipeline`), and LLMs (`HuggingFaceEndpoint`).\n",
        "- **QueryHandler Class**:\n",
        "  - **Initialization**: Sets up `Chroma` vectorstore, `BM25Retriever`, and an `EnsembleRetriever`. Initializes `spacy` models (English/French), a `facebook/bart-large-mnli` classifier for intent, a `distilbert-base-uncased-finetuned-sst-2-english` classifier for sentiment, a Mixtral-8x7B LLM, and stores prompt templates, metadata index, and analytics.\n",
        "  - **`detect_language`**: Identifies query language using a predefined function.\n",
        "  - **`classify_intent`**: Uses `facebook/bart-large-mnli` to classify query intents dynamically by generating candidate labels from `metadata_index` (e.g., 'query about Cryptography Policy') and a 'general query' fallback.\n",
        "  - **`classify_sentiment`**: Uses `distilbert-base-uncased-finetuned-sst-2-english` to classify query sentiment (positive, negative, neutral) with confidence scores, returning the predicted sentiment.\n",
        "  - **`optimize_retrieval_params`**: Adjusts retrieval parameters (`k`, weights) based on query and document count.\n",
        "  - **`optimize_temperature`**: Sets LLM temperature based on query complexity (0.7 for complex, 0.5 for simple) and sentiment (0.6 for negative to reduce creativity).\n",
        "  - **`expand_query`**: Rephrases queries using the LLM to improve retrieval accuracy.\n",
        "  - **`translate_response`**: Translates fallback messages (e.g., 'No procedure found') to match the query language.\n",
        "  - **`retrieve_documents`**: Asynchronously retrieves relevant documents using `EnsembleRetriever`, filtering by language.\n",
        "  - **`generate_response`**: Generates responses using the LLM with a single, general prompt template, incorporating context, chat history, inferred intent, and sentiment-driven tone.\n",
        "  - **`handle_query`**: Orchestrates query processing: cleans query, classifies intent and sentiment, retrieves documents, generates responses, and tracks analytics (e.g., response time, success rate).\n",
        "- **Logging and Output**: Logs and prints initialization and query handling outcomes for traceability.\n",
        "\n",
        "### Why It Matters\n",
        "The `QueryHandler` is the core of the chatbot’s query processing, integrating dynamic intent classification, sentiment analysis, document retrieval, and response generation to deliver accurate, bilingual, and sentiment-tailored responses. Its RAG approach, sentiment-driven tone adjustment, and optimization ensure efficient and user-centric answers, supporting the project’s goal of streamlined procedural information access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebfa80ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import asyncio\n",
        "from typing import List, Dict, Optional\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain.schema import Document\n",
        "from transformers import pipeline\n",
        "import spacy\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "class QueryHandler:\n",
        "    def __init__(self, vectorstore: Chroma, bm25_docs: List[str], prompt_templates: Dict, metadata_index: Dict):\n",
        "        try:\n",
        "            self.vectorstore = vectorstore\n",
        "            self.bm25_retriever = BM25Retriever.from_texts(bm25_docs)\n",
        "            self.bm25_retriever.k = 3\n",
        "            self.retriever = EnsembleRetriever(\n",
        "                retrievers=[self.vectorstore.as_retriever(search_kwargs={'k': 3}), self.bm25_retriever],\n",
        "                weights=[0.5, 0.5]\n",
        "            )\n",
        "            self.nlp_en = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "            self.nlp_fr = spacy.load('fr_core_news_sm', disable=['ner'])\n",
        "            self.intent_classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
        "            self.sentiment_classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
        "            self.llm = HuggingFaceEndpoint(\n",
        "                repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
        "                temperature=0.7,  # Default temperature\n",
        "                max_new_tokens=512,\n",
        "                huggingfacehub_api_token=os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
        "            )\n",
        "            self.prompt_templates = prompt_templates\n",
        "            self.metadata_index = metadata_index\n",
        "            self.chat_history = []\n",
        "            self.analytics = {'queries': 0, 'response_times': [], 'retrieval_scores': [], 'errors': [], 'success': 0}\n",
        "            logger.info(\"QueryHandler initialized with sentiment analysis support.\")\n",
        "            print(\"QueryHandler initialized with sentiment analysis support.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"QueryHandler init error: {str(e)}\")\n",
        "            raise ValueError(f\"Failed to initialize QueryHandler: {str(e)}\")\n",
        "\n",
        "    def detect_language(self, query: str) -> str:\n",
        "        return detect_language_from_prompt(query)\n",
        "\n",
        "    def classify_intent(self, query: str) -> str:\n",
        "        try:\n",
        "            language = self.detect_language(query)\n",
        "            nlp = self.nlp_en if language == 'en' else self.nlp_fr\n",
        "            doc = nlp(query)\n",
        "            query_clean = ' '.join(token.text.lower() for token in doc if not token.is_punct)\n",
        "            # Generate candidate intents dynamically from metadata_index\n",
        "            candidate_intents = [f\"query about {proc['title']}\" for proc in self.metadata_index.values()]\n",
        "            candidate_intents.append(\"general query\")  # Fallback for non-procedure-specific queries\n",
        "            # Use zero-shot classification to infer intent\n",
        "            result = self.intent_classifier(query_clean, candidate_labels=candidate_intents, multi_label=False)\n",
        "            predicted_intent = result['labels'][0]\n",
        "            confidence = result['scores'][0]\n",
        "            logger.debug(f\"Intent classified: {predicted_intent}, confidence={confidence}\")\n",
        "            return predicted_intent\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Intent classification failed: {str(e)}. Defaulting to 'general query'.\")\n",
        "            return \"general query\"\n",
        "\n",
        "    def classify_sentiment(self, query: str) -> str:\n",
        "        try:\n",
        "            language = self.detect_language(query)\n",
        "            nlp = self.nlp_en if language == 'en' else self.nlp_fr\n",
        "            doc = nlp(query)\n",
        "            query_clean = ' '.join(token.text.lower() for token in doc if not token.is_punct)\n",
        "            # Use sentiment classifier to infer sentiment\n",
        "            result = self.sentiment_classifier(query_clean)\n",
        "            label = result[0]['label'].lower()  # POSITIVE or NEGATIVE\n",
        "            score = result[0]['score']\n",
        "            # Map to positive, negative, or neutral based on score\n",
        "            if label == 'positive' and score > 0.7:\n",
        "                sentiment = 'positive'\n",
        "            elif label == 'negative' and score > 0.7:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            logger.debug(f\"Sentiment classified: {sentiment}, confidence={score}\")\n",
        "            return sentiment\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Sentiment classification failed: {str(e)}. Defaulting to 'neutral'.\")\n",
        "            return \"neutral\"\n",
        "\n",
        "    def optimize_retrieval_params(self, query: str, docs: List[Document]) -> tuple[int, List[float]]:\n",
        "        try:\n",
        "            k = min(len(docs), 5) if docs else 3\n",
        "            weights = [0.5, 0.5]\n",
        "            self.analytics['retrieval_scores'].append(1.0 if docs else 0.0)\n",
        "            logger.info(f\"Optimized retrieval params: k={k}, weights={weights}\")\n",
        "            return k, weights\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Retrieval optimization error: {str(e)}\")\n",
        "            return 3, [0.5, 0.5]\n",
        "\n",
        "    def optimize_temperature(self, query: str, sentiment: str) -> float:\n",
        "        try:\n",
        "            # Adjust temperature based on query length and sentiment\n",
        "            base_temperature = 0.7 if len(query.split()) > 10 else 0.5\n",
        "            if sentiment == 'negative':\n",
        "                temperature = 0.6  # Lower creativity for empathetic responses\n",
        "            else:\n",
        "                temperature = base_temperature\n",
        "            logger.info(f\"Optimized temperature: {temperature}, sentiment={sentiment}\")\n",
        "            return temperature\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Temperature optimization error: {str(e)}\")\n",
        "            return 0.7\n",
        "\n",
        "    def expand_query(self, query: str) -> str:\n",
        "        try:\n",
        "            if not isinstance(query, str) or not query.strip():\n",
        "                logger.warning(\"Invalid or empty query for expansion. Returning original query.\")\n",
        "                return str(query)\n",
        "            prompt = f\"Rephrase and expand the following query with synonyms to improve retrieval: '{query}'\"\n",
        "            expanded = self.llm.invoke(prompt)\n",
        "            return str(expanded).strip()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Query expansion error: {str(e)}\")\n",
        "            return str(query)\n",
        "\n",
        "    def translate_response(self, response: str, target_lang: str) -> str:\n",
        "        try:\n",
        "            if target_lang == 'fr' and 'No procedure found' in response:\n",
        "                return \"Aucune procédure trouvée.\"\n",
        "            elif target_lang == 'en' and 'Aucune procédure trouvée.' in response:\n",
        "                return \"No procedure found.\"\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Translation error: {str(e)}\")\n",
        "            return response\n",
        "\n",
        "    async def retrieve_documents(self, query: str, language: str) -> List[Document]:\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            docs = self.retriever.get_relevant_documents(query)\n",
        "            filtered_docs = [doc for doc in docs if doc.metadata.get('language') == language]\n",
        "            latency = time.time() - start_time\n",
        "            self.analytics['retrieval_scores'].append(1.0 if filtered_docs else 0.0)\n",
        "            logger.info(f\"Retrieved {len(filtered_docs)} documents in {latency:.2f} seconds\")\n",
        "            return filtered_docs\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Document retrieval failed: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    async def generate_response(self, query: str, intent: str, sentiment: str, context: str, procedure_name: Optional[str] = None) -> str:\n",
        "        try:\n",
        "            language = self.detect_language(query)\n",
        "            prompt_template = self.prompt_templates[language]['general']\n",
        "            chat_history_str = '\\n'.join([f\"Q: {h['query']}\\nA: {h['response']}\" for h in self.chat_history[-3:]])\n",
        "            prompt = prompt_template.format(\n",
        "                context=context,\n",
        "                chat_history=chat_history_str,\n",
        "                question=query,\n",
        "                intent=intent,\n",
        "                sentiment=sentiment,\n",
        "                procedure_name=procedure_name or 'Unknown'\n",
        "            )\n",
        "            self.llm.temperature = self.optimize_temperature(query, sentiment)\n",
        "            response = self.llm.invoke(prompt)\n",
        "            response = self.translate_response(response, language)\n",
        "            logger.debug(f\"Generated response for intent={intent}, sentiment={sentiment}, language={language}\")\n",
        "            return response.strip()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Response generation failed: {str(e)}\")\n",
        "            return \"Error generating response.\"\n",
        "\n",
        "    async def handle_query(self, query: str, session_id: str = 'default') -> str:\n",
        "        start_time = time.time()\n",
        "        self.analytics['queries'] += 1\n",
        "        try:\n",
        "            language = self.detect_language(query)\n",
        "            query_clean = re.sub(r'(?i)(answer in (english|french)|répondez en (français|anglais))', '', query).strip()\n",
        "            intent = self.classify_intent(query_clean)\n",
        "            sentiment = self.classify_sentiment(query_clean)\n",
        "            procedure_name = None\n",
        "            if intent.startswith('query about'):\n",
        "                nlp = self.nlp_en if language == 'en' else self.nlp_fr\n",
        "                doc = nlp(query_clean)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ in ['PRODUCT', 'ORG', 'PROCEDURE']:\n",
        "                        procedure_name = ent.text\n",
        "                        break\n",
        "                if not procedure_name:\n",
        "                    procedure_name = ' '.join(token.text for token in doc if token.pos_ == 'NOUN' and token.text.lower() not in ['procedure', 'procédure'])\n",
        "            expanded_query = self.expand_query(query_clean)\n",
        "            docs = await self.retrieve_documents(expanded_query, language)\n",
        "            k, weights = self.optimize_retrieval_params(expanded_query, docs)\n",
        "            self.retriever.retrievers[0].search_kwargs['k'] = k\n",
        "            self.retriever.weights = weights\n",
        "            context = '\\n'.join([doc.page_content for doc in docs])[:2000]\n",
        "            response_text = await self.generate_response(query_clean, intent, sentiment, context, procedure_name)\n",
        "            response = ChatbotResponse(\n",
        "                query=query,\n",
        "                intent=intent,\n",
        "                response=response_text,\n",
        "                language=language,\n",
        "                procedure_name=procedure_name,\n",
        "                analytics={'retrieval_time': time.time() - start_time, 'sentiment': sentiment}\n",
        "            )\n",
        "            self.chat_history.append({'query': query, 'response': response_text})\n",
        "            self.analytics['response_times'].append((time.time() - start_time) * 1000)\n",
        "            self.analytics['success'] += 1\n",
        "            logger.info(f\"Handled query: intent={intent}, sentiment={sentiment}, language={language}, response_length={len(response_text)}\")\n",
        "            return json.dumps(response.dict())\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Query handling failed: {str(e)}\")\n",
        "            self.analytics['errors'].append(str(e))\n",
        "            response = ChatbotResponse(\n",
        "                query=query,\n",
        "                intent='error',\n",
        "                response=f\"Error: {str(e)}\",\n",
        "                language=self.detect_language(query),\n",
        "                error=str(e),\n",
        "                analytics={'retrieval_time': time.time() - start_time, 'sentiment': 'neutral'}\n",
        "            )\n",
        "            return json.dumps(response.dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 5: Evaluation - Performance Assessment\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Evaluation** phase in CRISP-DM assesses the chatbot’s performance to ensure it meets project goals. For the bilingual procedure comparison chatbot, this phase evaluates intent classification accuracy, sentiment analysis accuracy, and response quality in English and French, using metrics like precision, recall, F1-score, cosine similarity, ROUGE, BLEU, and METEOR to validate effectiveness.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell evaluates the chatbot by processing test queries, measuring intent classification accuracy, sentiment classification accuracy, response quality, and response time. It uses a comprehensive set of metrics (precision, recall, F1-score for intent and sentiment, and cosine similarity, ROUGE, BLEU, METEOR for response quality) to assess performance, saving results for analysis.\n",
        "\n",
        "\n",
        "### What the Code Does\n",
        "- **Imports**: Includes libraries for JSON handling (`json`), timing (`time`), async processing (`asyncio`), statistics (`statistics`), embeddings (`sentence_transformers`), and evaluation metrics (`rouge_score`, `nltk.translate.bleu_score`, `nltk.translate.meteor_score`).\n",
        "- **Functions**:\n",
        "  - **`load_test_data`**: Loads test queries from `test_queries.json`, including expected intents, sentiments, and responses, or creates sample queries if missing, saving them to file.\n",
        "  - **`evaluate_response_quality`**: Computes:\n",
        "    - Cosine similarity (via `sentence_transformers`) for semantic similarity.\n",
        "    - ROUGE-1, ROUGE-2, ROUGE-L for text overlap.\n",
        "    - BLEU for n-gram precision.\n",
        "    - METEOR for synonym-aware, order-sensitive text quality.\n",
        "  - **`run_evaluation`**: Processes test queries asynchronously using `QueryHandler`, evaluates intent classification (precision, recall, F1-score), sentiment classification (precision, recall, F1-score), response quality (cosine similarity, ROUGE, BLEU, METEOR), and response times, then saves results to `evaluation_results.json`.\n",
        "- **Execution**: Initializes `PDFProcessor` and `QueryHandler`, runs evaluations, and logs/prints results.\n",
        "- **Logging and Output**: Logs metrics and errors, prints a summary of intent classification, sentiment classification, response quality, average response time, and error count.\n",
        "\n",
        "\n",
        "### Why It Matters\n",
        "This evaluation ensures the chatbot accurately interprets user intents and sentiments, generating high-quality, sentiment-aligned responses in both languages. The addition of sentiment analysis evaluation and ROUGE, BLEU, and METEOR provides a robust assessment of response quality and user experience, supporting the project’s goal of reliable procedural information delivery with a user-centric approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from time import time\n",
        "from typing import List, Dict, Any\n",
        "import asyncio\n",
        "import os\n",
        "from statistics import mean, stdev\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import single_meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def load_test_data(test_file: str = str(TEST_DATA_DIR / 'test_queries.json')) -> List[Dict]:\n",
        "    try:\n",
        "        if not os.path.exists(test_file):\n",
        "            logger.warning(f\"Test file {test_file} not found. Creating sample test data.\")\n",
        "            sample_data = [\n",
        "                {\n",
        "                    \"query\": \"List all procedures\",\n",
        "                    \"intent\": \"list\",\n",
        "                    \"expected_response\": \"1. Cryptography Policy\\n2. Data Backup Concept\\n3. ISMS Risk Management\",\n",
        "                    \"language\": \"en\"\n",
        "                },\n",
        "                {\n",
        "                    \"query\": \"What is the purpose of Cryptography Policy?\",\n",
        "                    \"intent\": \"question\",\n",
        "                    \"expected_response\": \"The purpose of the Cryptography Policy is to ensure secure data encryption.\",\n",
        "                    \"language\": \"en\"\n",
        "                },\n",
        "                {\n",
        "                    \"query\": \"Détails de la procédure 019110107Fr+\",\n",
        "                    \"intent\": \"detail\",\n",
        "                    \"expected_response\": \"**Procédure**: 019110107Fr+\\n**Objectif**: Démontrer des processus\\n**Étapes**:\\n1. Démarrer\\n2. Compléter\",\n",
        "                    \"language\": \"fr\"\n",
        "                },\n",
        "                {\n",
        "                    \"query\": \"Compare Cryptography Policy in English and French\",\n",
        "                    \"intent\": \"compare\",\n",
        "                    \"expected_response\": \"| Aspect | English | French |\\n|--------|---------|--------|\\n| Purpose | Secure encryption | Chiffrement sécurisé |\",\n",
        "                    \"language\": \"en\"\n",
        "                },\n",
        "                {\n",
        "                    \"query\": \"Execute Data Backup Concept\",\n",
        "                    \"intent\": \"execute\",\n",
        "                    \"expected_response\": \"Executing first step of 'Data Backup Concept': Initialize backup process\",\n",
        "                    \"language\": \"en\"\n",
        "                }\n",
        "            ]\n",
        "            os.makedirs(os.path.dirname(test_file), exist_ok=True)\n",
        "            with open(test_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(sample_data, f, indent=2, ensure_ascii=False)\n",
        "            logger.info(f\"Created sample test data with {len(sample_data)} queries at {test_file}\")\n",
        "            return sample_data\n",
        "        with open(test_file, 'r', encoding='utf-8') as f:\n",
        "            test_data = json.load(f)\n",
        "        logger.info(f\"Loaded {len(test_data)} test queries from {test_file}\")\n",
        "        return test_data\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading test data: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def evaluate_response_quality(responses: List[str], expected_responses: List[str]) -> Dict[str, float]:\n",
        "    try:\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        response_embeddings = model.encode(responses)\n",
        "        expected_embeddings = model.encode(expected_responses)\n",
        "        similarities = [\n",
        "            np.dot(r, e) / (np.linalg.norm(r) * np.linalg.norm(e))\n",
        "            for r, e in zip(response_embeddings, expected_embeddings)\n",
        "        ]\n",
        "        \n",
        "        # Initialize ROUGE scorer\n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
        "        bleu_scores = []\n",
        "        meteor_scores = []\n",
        "\n",
        "        for resp, exp in zip(responses, expected_responses):\n",
        "            # ROUGE scores\n",
        "            scores = scorer.score(exp, resp)\n",
        "            rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
        "            rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
        "            rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
        "            \n",
        "            # BLEU score\n",
        "            ref_tokens = [word_tokenize(exp.lower())]\n",
        "            hyp_tokens = word_tokenize(resp.lower())\n",
        "            bleu = sentence_bleu(ref_tokens, hyp_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "            bleu_scores.append(bleu)\n",
        "            \n",
        "            # METEOR score\n",
        "            meteor = single_meteor_score(word_tokenize(exp.lower()), word_tokenize(resp.lower()))\n",
        "            meteor_scores.append(meteor)\n",
        "\n",
        "        return {\n",
        "            'avg_cosine_similarity': mean(similarities) if similarities else 0.0,\n",
        "            'std_cosine_similarity': stdev(similarities) if len(similarities) > 1 else 0.0,\n",
        "            'avg_rouge1': mean(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0.0,\n",
        "            'avg_rouge2': mean(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0.0,\n",
        "            'avg_rougeL': mean(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0.0,\n",
        "            'avg_bleu': mean(bleu_scores) if bleu_scores else 0.0,\n",
        "            'avg_meteor': mean(meteor_scores) if meteor_scores else 0.0\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Response quality evaluation error: {str(e)}\")\n",
        "        return {\n",
        "            'avg_cosine_similarity': 0.0,\n",
        "            'std_cosine_similarity': 0.0,\n",
        "            'avg_rouge1': 0.0,\n",
        "            'avg_rouge2': 0.0,\n",
        "            'avg_rougeL': 0.0,\n",
        "            'avg_bleu': 0.0,\n",
        "            'avg_meteor': 0.0\n",
        "        }\n",
        "\n",
        "def run_evaluation(query_handler, test_data: List[Dict]) -> Dict[str, Any]:\n",
        "    results = {\n",
        "        'intent_metrics': {'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0},\n",
        "        'response_quality': {\n",
        "            'avg_cosine_similarity': 0.0,\n",
        "            'std_cosine_similarity': 0.0,\n",
        "            'avg_rouge1': 0.0,\n",
        "            'avg_rouge2': 0.0,\n",
        "            'avg_rougeL': 0.0,\n",
        "            'avg_bleu': 0.0,\n",
        "            'avg_meteor': 0.0\n",
        "        },\n",
        "        'response_times': [],\n",
        "        'errors': []\n",
        "    }\n",
        "    true_intents = []\n",
        "    predicted_intents = []\n",
        "    responses = []\n",
        "    expected_responses = []\n",
        "\n",
        "    async def evaluate_single_query(query_data: Dict) -> None:\n",
        "        try:\n",
        "            start_time = time()\n",
        "            query = query_data['query']\n",
        "            true_intent = query_data['intent']\n",
        "            expected_response = query_data['expected_response']\n",
        "            response_json = await query_handler.handle_query(query)\n",
        "            response_data = json.loads(response_json)\n",
        "            predicted_intent = response_data['intent']\n",
        "            response_text = response_data['response']\n",
        "\n",
        "            true_intents.append(true_intent)\n",
        "            predicted_intents.append(predicted_intent)\n",
        "            responses.append(response_text)\n",
        "            expected_responses.append(expected_response)\n",
        "\n",
        "            response_time = (time() - start_time) * 1000  # Convert to milliseconds\n",
        "            results['response_times'].append(response_time)\n",
        "            logger.info(f\"Evaluated query: {query}, Intent: {true_intent}, Response time: {response_time:.2f}ms\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Evaluation error for query '{query_data.get('query', 'unknown')}': {str(e)}\")\n",
        "            results['errors'].append(str(e))\n",
        "\n",
        "    async def run_async_evaluations():\n",
        "        tasks = [evaluate_single_query(query_data) for query_data in test_data]\n",
        "        await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    # Run evaluations\n",
        "    asyncio.run(run_async_evaluations())\n",
        "\n",
        "    # Evaluate intent classification\n",
        "    if true_intents and predicted_intents:\n",
        "        intent_metrics = evaluate_intent_classification(true_intents, predicted_intents)\n",
        "        results['intent_metrics'] = intent_metrics\n",
        "        logger.info(f\"Intent classification metrics: {intent_metrics}\")\n",
        "\n",
        "    # Evaluate response quality\n",
        "    if responses and expected_responses:\n",
        "        quality_metrics = evaluate_response_quality(responses, expected_responses)\n",
        "        results['response_quality'] = quality_metrics\n",
        "        logger.info(f\"Response quality metrics: {quality_metrics}\")\n",
        "\n",
        "    # Save results\n",
        "    try:\n",
        "        results_file = EVAL_RESULTS_DIR / 'evaluation_results.json'\n",
        "        os.makedirs(EVAL_RESULTS_DIR, exist_ok=True)\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "        logger.info(f\"Evaluation results saved to {results_file}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to save evaluation results: {str(e)}\")\n",
        "        results['errors'].append(f\"Failed to save results: {str(e)}\")\n",
        "\n",
        "    # Print summary\n",
        "    print(\"Evaluation Summary:\")\n",
        "    print(f\"Intent Classification: {results['intent_metrics']}\")\n",
        "    print(f\"Response Quality: {results['response_quality']}\")\n",
        "    print(f\"Average Response Time: {mean(results['response_times']):.2f}ms\" if results['response_times'] else \"No response times recorded\")\n",
        "    print(f\"Errors: {len(results['errors'])} encountered\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Initialize components and run evaluation\n",
        "try:\n",
        "    pdf_processor = PDFProcessor()\n",
        "    asyncio.run(pdf_processor.process_all_pdfs(english_files, french_files))\n",
        "    query_handler = QueryHandler(pdf_processor.vectorstore, pdf_processor.bm25_docs, PROMPT_TEMPLATES)\n",
        "    test_data = load_test_data()\n",
        "    evaluation_results = run_evaluation(query_handler, test_data)\n",
        "    logger.info(\"Evaluation completed successfully.\")\n",
        "    print(\"Evaluation completed successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Evaluation pipeline error: {str(e)}\")\n",
        "    print(f\"Evaluation failed: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 6: Deployment - Web Application\n",
        "\n",
        "## CRISP-DM Phase Overview\n",
        "The **Deployment** phase in CRISP-DM focuses on integrating the model into a production environment for end-user access. For the bilingual procedure comparison chatbot, this phase deploys the system as a web application, enabling users to interact with the chatbot via a browser in English and French.\n",
        "\n",
        "## Code Purpose\n",
        "This code cell sets up a Flask web application with a user-friendly interface and API endpoint for query processing, served by Waitress for production-grade performance. It ensures bilingual support and robust error handling for reliable deployment.\n",
        "\n",
        "### What the Code Does\n",
        "- **Imports**: Includes libraries for web development (`flask`), production serving (`waitress`), and async processing (`asyncio`).\n",
        "- **Flask Application**:\n",
        "  - Initializes a Flask app with two routes:\n",
        "    - `/`: Serves an HTML interface (`INDEX_HTML`) with a chat window, input field, and JavaScript for sending queries.\n",
        "    - `/query`: Handles POST requests, processes queries using `QueryHandler`, and returns JSON responses.\n",
        "  - Uses `render_template_string` for the HTML interface and `jsonify` for API responses.\n",
        "- **HTML Interface**: Provides a styled chat interface with user and bot message displays, supporting query input via button or Enter key.\n",
        "- **Query Handling**: Processes queries asynchronously with `QueryHandler`, supports session IDs, and includes error handling for invalid requests or server issues.\n",
        "- **Waitress Server**: Runs the Flask app on port 5000 with `waitress.serve` for stable, production-ready hosting.\n",
        "- **Initialization**: Sets up `PDFProcessor` and `QueryHandler`, processes PDFs, and starts the server.\n",
        "- **Logging and Output**: Logs server startup, query processing, and errors; prints deployment status.\n",
        "\n",
        "### Why It Matters\n",
        "This deployment makes the chatbot accessible to users via a web interface, supporting bilingual queries and ensuring reliability through robust error handling and production-grade serving. It completes the project’s goal of delivering procedural information interactively and efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from waitress import serve\n",
        "import asyncio\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# HTML template for the chatbot interface\n",
        "INDEX_HTML = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang='en'>\n",
        "<head>\n",
        "    <meta charset='UTF-8'>\n",
        "    <title>Procedure Comparison Chatbot</title>\n",
        "    <style>\n",
        "        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f4f4f9; }\n",
        "        h1 { color: #333; }\n",
        "        #chat-container { max-width: 600px; margin: auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }\n",
        "        #chat-history { height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; margin-bottom: 10px; background: #fafafa; }\n",
        "        #user-input { width: 80%; padding: 10px; margin-right: 10px; border: 1px solid #ccc; border-radius: 4px; }\n",
        "        #submit-btn { padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }\n",
        "        #submit-btn:hover { background: #0056b3; }\n",
        "        .message { margin: 5px 0; padding: 10px; border-radius: 4px; }\n",
        "        .user-message { background: #d4edda; }\n",
        "        .bot-message { background: #e9ecef; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div id='chat-container'>\n",
        "        <h1>Procedure Comparison Chatbot</h1>\n",
        "        <div id='chat-history'></div>\n",
        "        <input type='text' id='user-input' placeholder='Enter your query (e.g., List all procedures)'>\n",
        "        <button id='submit-btn' onclick='sendQuery()'>Send</button>\n",
        "    </div>\n",
        "    <script>\n",
        "        async function sendQuery() {\n",
        "            const input = document.getElementById('user-input').value;\n",
        "            if (!input.trim()) return;\n",
        "            addMessage('You: ' + input, 'user-message');\n",
        "            try {\n",
        "                const response = await fetch('/query', {\n",
        "                    method: 'POST',\n",
        "                    headers: { 'Content-Type': 'application/json' },\n",
        "                    body: JSON.stringify({ query: input, session_id: 'default' })\n",
        "                });\n",
        "                const data = await response.json();\n",
        "                addMessage('Bot: ' + data.response, 'bot-message');\n",
        "            } catch (error) {\n",
        "                addMessage('Bot: Error processing query.', 'bot-message');\n",
        "            }\n",
        "            document.getElementById('user-input').value = '';\n",
        "        }\n",
        "        function addMessage(text, className) {\n",
        "            const chatHistory = document.getElementById('chat-history');\n",
        "            const messageDiv = document.createElement('div');\n",
        "            messageDiv.className = 'message ' + className;\n",
        "            messageDiv.innerText = text;\n",
        "            chatHistory.appendChild(messageDiv);\n",
        "            chatHistory.scrollTop = chatHistory.scrollHeight;\n",
        "        }\n",
        "        document.getElementById('user-input').addEventListener('keypress', function(e) {\n",
        "            if (e.key === 'Enter') sendQuery();\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(INDEX_HTML)\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "async def handle_query():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        if not data or 'query' not in data:\n",
        "            logger.error(\"Invalid query request: Missing query field\")\n",
        "            return jsonify({'error': 'Query field is required'}), 400\n",
        "        query = data['query']\n",
        "        session_id = data.get('session_id', 'default')\n",
        "        response_json = await query_handler.handle_query(query, session_id)\n",
        "        response_data = json.loads(response_json)\n",
        "        logger.info(f\"Processed query via API: {query}, Session: {session_id}\")\n",
        "        return jsonify(response_data)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"API query error: {str(e)}\")\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "def run_server():\n",
        "    try:\n",
        "        logger.info(\"Starting Flask server with Waitress on port 5000...\")\n",
        "        serve(app, host='0.0.0.0', port=5000)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to start server: {str(e)}\")\n",
        "        print(f\"Server failed to start: {str(e)}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        # Ensure components are initialized\n",
        "        pdf_processor = PDFProcessor()\n",
        "        asyncio.run(pdf_processor.process_all_pdfs(english_files, french_files))\n",
        "        query_handler = QueryHandler(pdf_processor.vectorstore, pdf_processor.bm25_docs, PROMPT_TEMPLATES)\n",
        "        run_server()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Deployment initialization error: {str(e)}\")\n",
        "        print(f\"Deployment failed: {str(e)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
